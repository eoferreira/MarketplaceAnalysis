
# Marketplace Analysis

(English below)
Web scraping do marketplace (www.icarros.com.br) para análise no BigQuery. Os principais arquivos são:

## extract_scraper.py
Esse script percorre o site e baixa seus dados. Você pode pegar os dados de todo o marketplace ou filtrar o que quer baixar usando as condições que preferir. Isso pode ser feito usando os filtros do site e utilizando o URL resultante neste arquivo. O conteúdo extraído será salvo como arquivos JSON.

## transform_dump.py
Este script pega os arquivos JSON gerados pelo extract_scraper.py, realiza transformações, mescla os arquivos lidos e gera um arquivo do tipo newline delimited JSON que pode ser ingerido facilmente pelo BigQuery. Você pode filtrar quais marcas e modelos serão incluídos neste arquivo gerado.

## load_data.py
Este script pega o arquivo do tipo newline delimited JSON e faz o upload dele para uma tabela no BigQuery. Você pode configurar o nome do dataset, o nome da tabela (o script irá criar ambos para você se eles não existirem) e o schema que você quiser. Você irá precisar de ter um arquivo JSON com as suas credenciais do BigQuery (é possível obter esse arquivo ao criar uma Conta de Serviço no Google Cloud). Uma vez que esse script for executado e seus dados estiverem carregados, você poderá começar a realizar queries utilizando SQL, através da UI do BigQuery, etc.

## Respostas.ipynb
Esse notebook executa queries SQL na tabela que recebeu os dados no BigQuery e retorna algumas infromações extraídas dos dados e responde algumas perguntas sobre os dados.

## queries.sql
Este arquivo SQL contém queris utilizadas no notebook Resultados.ipynb.

## Resultados_DataStudio.pdf
PDF com visualização de resultados.

------------------

Web scraping of a marketplace (www.icarros.com.br) for analysis on BigQuery. The main files are the following:

## extract_scraper.py
This script crawls the website and scrapes its data. You can scrape the whole marketplace or filter by any conditions you want. The filtering can be done by setting the filters on the marketplace and copy and pasting the resulting URL on this file. The scraped content will be saved as JSON files.

## transform_dump.py
This script will get the JSON files generated by the extract_scraper.py, transform them and dump them together in a single newline delimited JSON that can be easily ingested by BigQuery. You can filter which brands or models you want to be in this new JSON file.

## load_data.py
This script will get the newline delimited JSON and upload it to a BigQuery table. You can easily set the BigQuery dataset name, table name (the script will create both for you if they don't exist) and the schema you want. You will need a JSON file with your BigQuery credentials (you can do this by setting up a Service Account on Google Cloud). Once this scripted is executed and your data is loaded, you can start querying it with SQL, using other scripts, the BigQuery UI or other solutions.

## Respostas.ipynb
This notebook queries the table on BigQuery using SQL to get some info about the data and answer a few questions about the data.

## queries.sql
This SQL file has some queries that were used on the Resultados.ipynb notebook.